{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "The focus of the project is to wrangle and visualize the dog information from the WeRateDogs twitter account. These will be achieved through the following steps which include;\n",
    "\n",
    "Gather and load the different data into jupyter notebook\n",
    "\n",
    "Assess the data to identify areas that needs cleaning\n",
    "\n",
    "Clean the data for further analysis\n",
    "\n",
    "Use different visualizations to analyse the data\n",
    "\n",
    "### Packages used in the project\n",
    "The packages used to gather, assess, clean and visualize the data include; pandas, numpy, requests, json, matplotlib, seaborn, re, warnings, tweepy, time, os\n",
    "\n",
    "### Data Gathering\n",
    "\n",
    "#### Twitter Archived Enhanced Data\n",
    "\n",
    "The data is provided as \"twitter-archive-enhanced.csv\" and would be import used pandas read function. This was loaded into the jupyter notebook using pandas.\n",
    "\n",
    "#### Image prediction Data\n",
    "The tweet image predictions, i.e., what breed of dog, is present in each tweet was based on neural network. The link to the data  (image_predictions.tsv) stored in Udacity server was provided  and was downloaded using request and loaded using pandas.\n",
    "Provide information on iDownload data from link provided programmatically and read using pandas read function and then saved. The code for download had be converted to a comment to avoid download multiple time during the project\n",
    "\n",
    "#### Tweets data\n",
    "\n",
    "In order to avoid delays while requesting for a developer account, we make use of the json file (tweet_json.txt) provided containing tweets data. The data contain more information gotten through Twitter's API such as favorite count, retweets e.t.c. which ae required for a roboust analysis. .  We read file and then create a dataframe usin details from the file\n",
    "\n",
    "All three data were gathered and loaded into pandas dataframes. (tweets_archive, image_pred and tweets_data)\n",
    "\n",
    "### Assess Data\n",
    "The three dataframe will be assessed using pandas functions and methods (head,info, shape, describe, sample e.t.c). After Assessing the data several issues (Quality and Tidyness) were discovered in the data. The table beloow show the summary of the issues identified\n",
    "Based on the assessment performed the issues identified for cleaning in this project are presented in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISSUE</th>\n",
       "      <th>DATA</th>\n",
       "      <th>ISSUE TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some column are not need so they should dropped (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Tidiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Timestamp is in int64 format and needs to be convert timestamp to datetime format for easy manipulation</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unrealitic rating values are in the rating numerator and denominator and should be removed. This will be removed using outlier analysis.</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rating numerator and denominator need to be in float format rather than int64</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Create a rating column</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Convert source to readable format by extract by extract tweet source from the source link provided</td>\n",
       "      <td>twee_archive</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remove rows where p1_dog,p2_dog,p3_dog are false because they are most likely not dogs</td>\n",
       "      <td>image_pred</td>\n",
       "      <td>Tidness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Drop p1_dog,p2_dog,p3_dog columns since we have selected rows which are most likely dogs. Also drop img_num as it is not relevant</td>\n",
       "      <td>image_pred</td>\n",
       "      <td>Tidiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rename 'p1', 'p1_conf', 'p2', 'p2_conf', 'p3', 'p3_conf' to more descriptive names</td>\n",
       "      <td>image_pred</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Remove '_' from names and capitalize the first letter of each names.</td>\n",
       "      <td>image_pred</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value</td>\n",
       "      <td>image_pred</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timestamp is in int64 format and needs to be convert timestamp to datetime format for easy manipulation</td>\n",
       "      <td>tweet_data</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value</td>\n",
       "      <td>tweet_data</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The User_id is same value all through and should be dropped as it is irrelevant for analysis.</td>\n",
       "      <td>tweet_data</td>\n",
       "      <td>Tidness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Merge the three dataset into a single dataframe (tweet_data_master). Merging was done on tweet_id and timestamp.</td>\n",
       "      <td>tweet_data_master</td>\n",
       "      <td>Tidness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Capitalize column names in the merged dataset</td>\n",
       "      <td>tweet_data_master</td>\n",
       "      <td>Quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Extract day, month and year from timestamp in the merged dataset</td>\n",
       "      <td>tweet_data_master</td>\n",
       "      <td>Tidness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      ISSUE  \\\n",
       "0   Some column are not need so they should dropped (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)   \n",
       "1   Timestamp is in int64 format and needs to be convert timestamp to datetime format for easy manipulation                                                                   \n",
       "2   tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value                                                       \n",
       "3   Unrealitic rating values are in the rating numerator and denominator and should be removed. This will be removed using outlier analysis.                                  \n",
       "4   Rating numerator and denominator need to be in float format rather than int64                                                                                             \n",
       "5   Create a rating column                                                                                                                                                    \n",
       "6   Convert source to readable format by extract by extract tweet source from the source link provided                                                                        \n",
       "7   NaN                                                                                                                                                                       \n",
       "8   Remove rows where p1_dog,p2_dog,p3_dog are false because they are most likely not dogs                                                                                    \n",
       "9   Drop p1_dog,p2_dog,p3_dog columns since we have selected rows which are most likely dogs. Also drop img_num as it is not relevant                                         \n",
       "10  Rename 'p1', 'p1_conf', 'p2', 'p2_conf', 'p3', 'p3_conf' to more descriptive names                                                                                        \n",
       "11  Remove '_' from names and capitalize the first letter of each names.                                                                                                      \n",
       "12  tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value                                                       \n",
       "13  NaN                                                                                                                                                                       \n",
       "14  Timestamp is in int64 format and needs to be convert timestamp to datetime format for easy manipulation                                                                   \n",
       "15  tweet_id is currently in int64 format and will be converted to string since it is actually not a quantitative value                                                       \n",
       "16  The User_id is same value all through and should be dropped as it is irrelevant for analysis.                                                                             \n",
       "17  NaN                                                                                                                                                                       \n",
       "18  Merge the three dataset into a single dataframe (tweet_data_master). Merging was done on tweet_id and timestamp.                                                          \n",
       "19  Capitalize column names in the merged dataset                                                                                                                             \n",
       "20  Extract day, month and year from timestamp in the merged dataset                                                                                                          \n",
       "\n",
       "                 DATA ISSUE TYPE  \n",
       "0   twee_archive       Tidiness   \n",
       "1   twee_archive       Quality    \n",
       "2   twee_archive       Quality    \n",
       "3   twee_archive       Quality    \n",
       "4   twee_archive       Quality    \n",
       "5   twee_archive       Quality    \n",
       "6   twee_archive       Quality    \n",
       "7   NaN                NaN        \n",
       "8   image_pred         Tidness    \n",
       "9   image_pred         Tidiness   \n",
       "10  image_pred         Quality    \n",
       "11  image_pred         Quality    \n",
       "12  image_pred         Quality    \n",
       "13  NaN                NaN        \n",
       "14  tweet_data         Quality    \n",
       "15  tweet_data         Quality    \n",
       "16  tweet_data         Tidness    \n",
       "17  NaN                NaN        \n",
       "18  tweet_data_master  Tidness    \n",
       "19  tweet_data_master  Quality    \n",
       "20  tweet_data_master  Tidness    "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "Issues = pd.read_csv(\"issues identified.csv\")\n",
    "Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "This phase was the most challenging of the project. Some of the identified issues were actually easy while some seems tough initially. I had to do alot of google seach, read through post on stackoverflow. I also had to learn to read and understand documentation for pandas, seaborn and i really loved it (actually discovered alot of tips from this). I found working with datetime data interesting\n",
    "\n",
    "Overall i learnt have learnt how to make sense how of  very low quality and untidy data.\n",
    "\n",
    "Data cleaning was done and a final master data was generated by merging all the cleaned data together.\n",
    "\n",
    "I created some visual insights into the data and a report was also made (act_report)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
